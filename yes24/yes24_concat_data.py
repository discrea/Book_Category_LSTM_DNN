# -*- coding: utf-8 -*-
"""yes24_concat_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/110AheY2RfPr9OVm8kU3saHal56AzOzaE
"""

import os
import re
import pickle
import numpy as np
import pandas as pd
from konlpy.tag import Okt

def search(dirname):                    # 디렉토리에 있는 중분류 데이터들 리스트로 주소 읽어오는 함수
    filenames = os.listdir(dirname)
    full_filename = []
    for filename in filenames:
        full_filename.append(os.path.join(dirname, filename))
    return full_filename

filename = search("../data")
# raw data set
raw_data = pd.DataFrame(index=range(1), columns=['Title', 'Medium_category', 'Small_category', 'Introduction'])

for dir in filename:                        # 데이터 하나씩 가져와서
    temp = pd.read_csv(dir, index_col=0)
    print('#'*60)
    print(temp.info())
    raw_data = pd.concat([raw_data, temp])  # raw data에 붙이기

raw_data = raw_data.reset_index(drop=True)
raw_data.dropna(inplace=True)                   # 널값 제거
df = raw_data
df['cnt'] = 1
df.drop_duplicates(inplace=True)                            # 중복 제거 1
df.drop_duplicates(subset=['Introduction'],inplace=True)    # 중복 제거 2
cat_df_m = df[['Medium_category','cnt']].groupby(['Medium_category']).sum()     # 중분류 별 데이터 분석 후 데이터가 너무 적은 카테고리는 날림
cut_small_data = df[df['cnt'] > 2481.347826]                                    # 중분류 중간값
extracted_data = raw_data[raw_data.Medium_category.isin(list(cut_small_data.index))]
# 책 소개 부분의 기호, 널값, 개행 삭제
extracted_data['Introduction'] = extracted_data['Introduction'].apply(lambda x: re.compile('[^가-힣 | a-z | A-Z | 0-9 ]').sub(' ', x))
extracted_data.to_csv('../data/raw_data.csv')